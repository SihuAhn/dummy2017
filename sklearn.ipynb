{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'images', 'target', 'target_names']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "dir(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "print(digits.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "plt.imshow(digits.images[500], cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "print(digits.target[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0wAAAE/CAYAAAB1tEPxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFRNJREFUeJzt3W9sXvd1H/BzEgZLEzckvbXB1m2hVLRr13Z6HOfVhkw0Ji1rhoFPt1rI1qVisMJGghSh0BbSiwyi0w61gGGl0D+bCwSmtgwDbCCltrZoES+msBbYVgumChTN0iai23Qx2jSkmqSJ16W/vaACBF6O/twflUtZnw9A2Cbw5TkmL+9zv7wPH2ZrLQAAAPj/vWrsBQAAAA4qhQkAAKCgMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWHqlJn3Z+YvZOYXMvOFzPxnY+8EN5KZ783M5zLzpcxcH3sfuJnM/AuZ+cHr59jPZebzmfm9Y+8FN5KZH8rMT2fmn2TmxzPzh8beCW5FZn5bZn4pMz809i4HxczYC7wC/GxE/J+IeGNETCLilzLzSmvtt8ZdC0r/OyJ+IiLeFhHfMPIucCtmIuL3I+JoRPxeRLw9Ip7KzO9prW2PuRjcwE9GxL9orb2Umd8REZuZ+Xxr7fLYi8FN/GxE/MbYSxwk7jB1yMzXR8Q/iYh/2Vr7fGvt1yLiP0fEO8fdDGqttQ+31jYi4o/H3gVuRWvtC6211dbadmvtz1trvxgRVyPiwbF3g0pr7bdaay995T+vv33riCvBTWXmOyJiNyL+69i7HCQKU59vj4gvt9Y+/lXvuxIR3zXSPgCveJn5xtg7/7qTz4GWmT+XmX8aER+LiE9HxC+PvBKUMvMNEfGBiPiRsXc5aBSmPvdFxLWXve9aRHzjCLsAvOJl5msi4j9GxIXW2sfG3gdupLX2nti7JnhrRHw4Il66cQJG9eMR8cHW2u+PvchBozD1+XxEvOFl73tDRHxuhF0AXtEy81UR8R9i7/dG3zvyOnBLWmtfvv6U/b8aEe8eex/4WjJzEhHHIuKnxt7lIPKiD30+HhEzmfltrbXfuf6+I+FpIgD7KjMzIj4Yey+w8/bW2p+NvBLcrpnwO0wcXIsRsRARv7d3uo37IuLVmfk3W2tvHnGvA8Edpg6ttS/E3i32D2Tm6zPz70TEUuz9BBQOpMycyczXRsSrY+9k+NrM9MMTDrp/GxHfGRH/qLX2xbGXgRvJzG/OzHdk5n2Z+erMfFtE/NOI+OjYu0Hh52Ov0E+uv/27iPil2HtF3XuewtTvPbH30sx/GBH/KSLe7SXFOeDeHxFfjIgzEfHPr//7+0fdCG4gM98UEY/G3oP4i5n5+etvPzDyalBpsff0u09FxE5E/OuIWGmtXRx1Kyi01v60tfbiV95i79dOvtRa+6OxdzsIsrU29g4AAAAHkjtMAAAABYUJAACgoDABAAAUFCYAAICCwgQAAFC4U397ZbSX3nv66acHZ0+fPt01+/jx44Ozjz/+eNfs+fn5rnynHHP4PrkrXy5ycXGxK7+7uzs4+9hjj3XNXlpa6sp3csyOZHNzsys/nU4HZyeTSdfs3t07OWY7nDt3bnD2zJkzXbMPHTo0OHv58uWu2a4Nut2V59mex/aIiOXl5cHZjY2NrtkjK49Zd5gAAAAKChMAAEBBYQIAACgoTAAAAAWFCQAAoKAwAQAAFBQmAACAgsIEAABQUJgAAAAKChMAAEBBYQIAACgoTAAAAAWFCQAAoKAwAQAAFGbGXmC/nT59enD26tWrXbN3dnYGZ++///6u2U899dTg7MMPP9w1m/HMzc115S9dujQ4++yzz3bNXlpa6soznq2trcHZhx56qGv27Ozs4Oz29nbXbMZz5syZrnzPY+QTTzzRNfvRRx8dnL18+XLX7GPHjnXluTutr6935SeTyf4s8griDhMAAEBBYQIAACgoTAAAAAWFCQAAoKAwAQAAFBQmAACAgsIEAABQUJgAAAAKChMAAEBBYQIAACgoTAAAAAWFCQAAoKAwAQAAFBQmAACAgsIEAABQmBl7gZe7fPlyV/7q1auDs5/4xCe6Zh8+fHhw9vjx412zez5vDz/8cNds+mxtbQ3Obm5u7t8it2kymYw2m3FtbGwMzh45cqRr9nQ6HZx97LHHumYznkceeaQrf/r06cHZBx98sGv2oUOHBmePHTvWNZu71+7u7uDs+vp61+yVlZXB2e3t7a7ZPRYWFu7Yx3aHCQAAoKAwAQAAFBQmAACAgsIEAABQUJgAAAAKChMAAEBBYQIAACgoTAAAAAWFCQAAoKAwAQAAFBQmAACAgsIEAABQUJgAAAAKChMAAEBhZuwFXm5nZ6cr/+Y3v3lw9vDhw12zezz44IOjzabP2tpaV351dXVw9tq1a12zeywuLo42m3GtrKwMzi4sLIw2e2lpqWs24+l9fP7kJz85OHv16tWu2ceOHRuc7b0mmp+f78oznvX19cHZ7e3trtnLy8uDsz3n6IiIubm5wdme66mbcYcJAACgoDABAAAUFCYAAICCwgQAAFBQmAAAAAoKEwAAQEFhAgAAKChMAAAABYUJAACgoDABAAAUFCYAAICCwgQAAFBQmAAAAAoKEwAAQEFhAgAAKMyMvcDL7ezsdOWPHz++T5t8ffX+f8/Pz+/TJtyulZWVrvzy8vLg7Jhf993d3dFm06f3a7e2tjY4u7Gx0TW7x/r6+mizGdfhw4cHZz/72c92zT527Ngo2YiIZ555ZnDWdUWfixcvduVPnTo1OHvy5Mmu2T3Onz/flX/yySf3aZP95Q4TAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABQUJgAAgMLM2Au83Pz8fFf+8uXL+7TJ7dvZ2Rmcfe6557pmnzhxoisPt2tra6srP5lM9mkTbtfq6mpX/vz58/uzyAAbGxuDs3Nzc/u4CfeK3uuSZ555ZnD20Ucf7Zp97ty5wdnHH3+8a/a9bnZ2drT8hQsXumb3Pr73mE6no82+EXeYAAAACgoTAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABQUJgAAgMLM2Au83OHDh7vyzz333ODs008/3TW7N9/j9OnTo80G7i7Ly8td+c3NzcHZK1eudM2eTqeDs0tLS12z3/Wud402mz5nzpwZnD127FjX7J2dncHZj3zkI12zT5w40ZVnuMXFxa787u7u4OzW1lbX7J7dT5482TV7bm6uK3+nuMMEAABQUJgAAAAKChMAAEBBYQIAACgoTAAAAAWFCQAAoKAwAQAAFBQmAACAgsIEAABQUJgAAAAKChMAAEBBYQIAACgoTAAAAAWFCQAAoDAz9gIvd/jw4a78uXPnBmdPnz7dNfstb3nL4Ozly5e7ZnP3mpubG5xdWlrqmn3x4sXB2c3Nza7Zy8vLXXmGm0wmXfmtra1RshERq6urg7M9x3tExMLCwuBs7/cqfebn5wdnH3nkkX3c5PacOHGiK//EE0/s0ybcTXquKyIirl27Njj7Sn1sd4cJAACgoDABAAAUFCYAAICCwgQAAFBQmAAAAAoKEwAAQEFhAgAAKChMAAAABYUJAACgoDABAAAUFCYAAICCwgQAAFBQmAAAAAoKEwAAQEFhAgAAKGRrbewdAAAADiR3mAAAAAoKEwAAQEFhAgAAKChMAAAABYUJAACgoDABAAAUFCYAAICCwgQAAFBQmDpl5mZmfikzP3/97X+NvRPcisx8R2b+dmZ+ITM/kZlvHXsn+Fq+6vz6lbcvZ+ZPj70X3EhmLmTmL2fmTma+mJk/k5kzY+8Flcz8zsz8aGZey8zfzczvG3ung0Jh2h/vba3dd/3tb4y9DNxMZh6PiHMR8a6I+MaI+LsR8clRl4LCV51f74uIN0bEFyPi6ZHXgpv5uYj4w4j4yxExiYijEfGeUTeCwvUyfzEifjEi7o+IRyLiQ5n57aMudkAoTHBveiwiPtBa+++ttT9vrf1Ba+0Pxl4KbsH3x95F6H8bexG4iUMR8VRr7UuttRcj4lci4rtG3gkq3xERfyUifqq19uXW2kcj4tcj4p3jrnUwKEz74ycz8zOZ+euZuTj2MnAjmfnqiHhLRHzT9Vvun7r+VJFvGHs3uAUnI+Lft9ba2IvATZyPiHdk5usy81si4ntjrzTBQZTF+777673IQaQw9TsdEYcj4lsi4ucj4r9k5reOuxLc0Bsj4jWx95P6t8beU0UeiIj3j7kU3Exm/vXYe1rThbF3gVtwKfbuKP1JRHwqIp6LiI1RN4Lax2Lv7v2PZeZrMvPvx9759nXjrnUwKEydWmv/o7X2udbaS621C7F3+/LtY+8FN/DF6//86dbap1trn4mIfxOOWw6+H4yIX2utXR17EbiRzHxVRPxqRHw4Il4fEX8pIuZj73dH4cBprf1ZREwj4h9GxIsR8SMR8VTslf17nsK0/1p87duacCC01nZi7wToKU3cbX4w3F3i7nB/RPy1iPiZ6z9Q/eOIeDL8YIoDrLX2m621o621v9hae1vsPYPqf46910GgMHXIzLnMfFtmvjYzZzLzB2Lv1cZ+dezd4CaejIgfzsxvzsz5iFiJvVfGgQMpM/927D312avjceBdv3N/NSLeff36YC72fv/uyribQS0z/9b1a9rXZeaPxt4rPK6PvNaBoDD1eU1E/ERE/FFEfCYifjgipq01f4uJg+7HI+I3IuLjEfHbEfF8RPyrUTeCGzsZER9urX1u7EXgFv3jiPgHsXeN8LsR8X8j4tSoG8GNvTMiPh17v8v09yLieGvtpXFXOhjSCw0BAAB8be4wAQAAFBQmAACAgsIEAABQUJgAAAAKChMAAEBh5g593NFeem9xcXFwdmFhoWv2+vp6V/4u9kr4Q7135ctF9hzvERG7u7uDs1tbW12zR+aY7bC2tjY423PMRURsbGwMzl650vcncGZnZwdnt7e3u2bPzc05ZjusrKwMzvYccxERy8vLg7M9e0dEzM3NdeU7OWY7TKfTwdne8+zm5mZX/i5WHrPuMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWECAAAoZGvtTnzcO/JBb8XCwsLg7AsvvLB/i9ymN73pTV357e3t/VlkmBxz+D4Z7Zi9ePHi4Ox0Ou2affbs2cHZ1dXVrtkjc8x2WFtbG2t0TCaTwdnevXd3dwdnNzc3u2aHY7bL4uLi4OyYj6891zQR+3Lc9binj9ne4+bQoUNd+bEcOXKkK7+1tbVPmwxSHrPuMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWECAAAoKEwAAACFmbEX2G9zc3ODsy+88ELX7NnZ2cHZxcXFrtm7u7uDsz2fM/qdPXt2tNnT6XS02dy9VlZWRpu9uro6OLu9vd01e3NzsyvPeCaTyeDswsJC1+z19fXB2d7H555jtve65F7Xc13W6+jRo135nmP+lXqedIcJAACgoDABAAAUFCYAAICCwgQAAFBQmAAAAAoKEwAAQEFhAgAAKChMAAAABYUJAACgoDABAAAUFCYAAICCwgQAAFBQmAAAAAoKEwAAQGFm7AX228LCwuDslStXumZfu3ZtcHYymXTNnpub68oznt3d3cHZI0eOdM3uPe64O21ubo6a77G2tjba7I2NjcHZ5eXl/VuE29bz+X/ggQe6Zm9vbw/O9j6291wT0WfMz33PuSoiYjqdDs72XNMcZO4wAQAAFBQmAACAgsIEAABQUJgAAAAKChMAAEBBYQIAACgoTAAAAAWFCQAAoKAwAQAAFBQmAACAgsIEAABQUJgAAAAKChMAAEBBYQIAACgoTAAAAIWZsRfYbxsbG4Ozm5ubXbO3trYGZ0+dOtU1u8fKyspos4nY3d0dnF1YWOiavba2Njg7nU67ZvfuznC9n/uec13vebZHz+NDRMTi4uL+LMLXXc95ttelS5cGZ69evdo123l2PHNzc135I0eODM7Oz893zX7f+943ONvz+BARsb29PTh7J493d5gAAAAKChMAAEBBYQIAACgoTAAAAAWFCQAAoKAwAQAAFBQmAACAgsIEAABQUJgAAAAKChMAAEBBYQIAACgoTAAAAAWFCQAAoKAwAQAAFGbGXuAgWVxcHHuFwba3t8degYEWFhYGZy9dutQ1e3d3d3D21KlTXbOff/75wdnJZNI1+17Xc8xFRGxsbAzOZuZos+/mc/y9bmtrqyv/0EMPDc6ePXu2a3bP4/N0Ou2a3fP90nueoE/PMd/7/TLmY+zKysrgbM/xfjPuMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWECAAAoKEwAAACFmbEX2G8XL14cnJ2dne2avbq62pXvMZ1OR5tNn+Xl5cHZU6dOdc1eWFgYnN3e3u6avbGxMTg7mUy6ZtNnZWVlcLb3PHv06NGuPHennnNVRN9x13O8R/SdKx944IGu2evr64OzY17T0Kf3MbLnmO855iL6rg3uJHeYAAAACgoTAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABRmxl5gvz377LODs+fPn9/HTW7PyZMnu/KLi4v7swhfd8vLy4Oz29vbXbPX19cHZ3uPuel02pVnPJubm4OzFy5c6Jo9NzfXlefu1Pt17zlfzc/Pd82enZ0dnF1aWuqavbKy0pVnPD1fu62tra7Zu7u7g7M9jw8REZPJpCt/p7jDBAAAUFCYAAAACgoTAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABSytTb2DgAAAAeSO0wAAAAFhQkAAKCgMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABAQWECAAAoKEwAAAAFhQkAAKCgMAEAABQUJgAAgILCBAAAUFCYAAAACgoTAABA4f8Bpv7jAMJlvGwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "for i in range(0,10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(digits.images[i], cmap='binary')\n",
    "    plt.title(digits.target[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "x = digits.images.reshape(digits.images.shape[0],digits.images.shape[1]*digits.images.shape[2])\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "x = digits.images.reshape(digits.images.shape[0],digits.images.shape[1]*digits.images.shape[2])\n",
    "\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.] 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "x = digits.images.reshape(digits.images.shape[0],digits.images.shape[1]*digits.images.shape[2])\n",
    "\n",
    "y = digits.target\n",
    "print(x[0],y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "x = digits.images.reshape(digits.images.shape[0],digits.images.shape[1]*digits.images.shape[2])\n",
    "\n",
    "y = digits.target\n",
    "\n",
    "x_train = x[:1000]\n",
    "y_train = y[:1000]\n",
    "x_test = x[1000:]\n",
    "y_test = y[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.30766655\n",
      "Iteration 2, loss = 1.96993547\n",
      "Iteration 3, loss = 1.66324184\n",
      "Iteration 4, loss = 1.34870214\n",
      "Iteration 5, loss = 1.04843578\n",
      "Iteration 6, loss = 0.80462196\n",
      "Iteration 7, loss = 0.62411054\n",
      "Iteration 8, loss = 0.48766305\n",
      "Iteration 9, loss = 0.39243711\n",
      "Iteration 10, loss = 0.32322104\n",
      "Iteration 11, loss = 0.27263614\n",
      "Iteration 12, loss = 0.23851591\n",
      "Iteration 13, loss = 0.20371983\n",
      "Iteration 14, loss = 0.18221481\n",
      "Iteration 15, loss = 0.16331579\n",
      "Iteration 16, loss = 0.14993457\n",
      "Iteration 17, loss = 0.13601040\n",
      "Iteration 18, loss = 0.12578396\n",
      "Iteration 19, loss = 0.11754682\n",
      "Iteration 20, loss = 0.11052484\n",
      "Iteration 21, loss = 0.10307738\n",
      "Iteration 22, loss = 0.09742174\n",
      "Iteration 23, loss = 0.09005674\n",
      "Iteration 24, loss = 0.08751715\n",
      "Iteration 25, loss = 0.08197002\n",
      "Iteration 26, loss = 0.07751833\n",
      "Iteration 27, loss = 0.07462666\n",
      "Iteration 28, loss = 0.07123202\n",
      "Iteration 29, loss = 0.06850620\n",
      "Iteration 30, loss = 0.06586470\n",
      "Iteration 31, loss = 0.06238709\n",
      "Iteration 32, loss = 0.06027635\n",
      "Iteration 33, loss = 0.05940902\n",
      "Iteration 34, loss = 0.05675545\n",
      "Iteration 35, loss = 0.05472771\n",
      "Iteration 36, loss = 0.05300375\n",
      "Iteration 37, loss = 0.05108103\n",
      "Iteration 38, loss = 0.04967307\n",
      "Iteration 39, loss = 0.04879717\n",
      "Iteration 40, loss = 0.04688088\n",
      "Iteration 41, loss = 0.04577624\n",
      "Iteration 42, loss = 0.04396556\n",
      "Iteration 43, loss = 0.04271009\n",
      "Iteration 44, loss = 0.04170434\n",
      "Iteration 45, loss = 0.04047899\n",
      "Iteration 46, loss = 0.03957478\n",
      "Iteration 47, loss = 0.03857923\n",
      "Iteration 48, loss = 0.03756082\n",
      "Iteration 49, loss = 0.03700335\n",
      "Iteration 50, loss = 0.03573216\n",
      "Iteration 51, loss = 0.03531760\n",
      "Iteration 52, loss = 0.03425517\n",
      "Iteration 53, loss = 0.03347301\n",
      "Iteration 54, loss = 0.03322227\n",
      "Iteration 55, loss = 0.03231040\n",
      "Iteration 56, loss = 0.03168497\n",
      "Iteration 57, loss = 0.03097878\n",
      "Iteration 58, loss = 0.03045831\n",
      "Iteration 59, loss = 0.02966679\n",
      "Iteration 60, loss = 0.02929106\n",
      "Iteration 61, loss = 0.02869613\n",
      "Iteration 62, loss = 0.02843302\n",
      "Iteration 63, loss = 0.02778357\n",
      "Iteration 64, loss = 0.02762447\n",
      "Iteration 65, loss = 0.02675909\n",
      "Iteration 66, loss = 0.02640284\n",
      "Iteration 67, loss = 0.02593005\n",
      "Iteration 68, loss = 0.02562886\n",
      "Iteration 69, loss = 0.02529169\n",
      "Iteration 70, loss = 0.02486895\n",
      "Iteration 71, loss = 0.02458279\n",
      "Iteration 72, loss = 0.02416639\n",
      "Iteration 73, loss = 0.02384323\n",
      "Iteration 74, loss = 0.02352451\n",
      "Iteration 75, loss = 0.02315170\n",
      "Iteration 76, loss = 0.02280309\n",
      "Iteration 77, loss = 0.02253637\n",
      "Iteration 78, loss = 0.02225613\n",
      "Iteration 79, loss = 0.02199094\n",
      "Iteration 80, loss = 0.02160732\n",
      "Iteration 81, loss = 0.02134530\n",
      "Iteration 82, loss = 0.02107936\n",
      "Iteration 83, loss = 0.02086948\n",
      "Iteration 84, loss = 0.02051469\n",
      "Iteration 85, loss = 0.02035700\n",
      "Iteration 86, loss = 0.02015284\n",
      "Iteration 87, loss = 0.02001088\n",
      "Iteration 88, loss = 0.01959916\n",
      "Iteration 89, loss = 0.01938436\n",
      "Iteration 90, loss = 0.01922011\n",
      "Iteration 91, loss = 0.01892668\n",
      "Iteration 92, loss = 0.01878500\n",
      "Iteration 93, loss = 0.01856578\n",
      "Iteration 94, loss = 0.01846124\n",
      "Iteration 95, loss = 0.01820588\n",
      "Iteration 96, loss = 0.01798343\n",
      "Iteration 97, loss = 0.01774091\n",
      "Iteration 98, loss = 0.01757575\n",
      "Iteration 99, loss = 0.01736589\n",
      "Iteration 100, loss = 0.01718905\n",
      "Iteration 101, loss = 0.01702673\n",
      "Iteration 102, loss = 0.01693141\n",
      "Iteration 103, loss = 0.01676703\n",
      "Iteration 104, loss = 0.01650689\n",
      "Iteration 105, loss = 0.01641465\n",
      "Iteration 106, loss = 0.01625499\n",
      "Iteration 107, loss = 0.01608674\n",
      "Iteration 108, loss = 0.01597357\n",
      "Iteration 109, loss = 0.01578612\n",
      "Iteration 110, loss = 0.01565347\n",
      "Iteration 111, loss = 0.01553182\n",
      "Iteration 112, loss = 0.01537647\n",
      "Iteration 113, loss = 0.01523000\n",
      "Iteration 114, loss = 0.01510311\n",
      "Iteration 115, loss = 0.01500527\n",
      "Iteration 116, loss = 0.01484484\n",
      "Iteration 117, loss = 0.01474526\n",
      "Iteration 118, loss = 0.01457802\n",
      "Iteration 119, loss = 0.01446377\n",
      "Iteration 120, loss = 0.01434391\n",
      "Iteration 121, loss = 0.01426704\n",
      "Iteration 122, loss = 0.01410824\n",
      "Iteration 123, loss = 0.01399775\n",
      "Iteration 124, loss = 0.01393268\n",
      "Iteration 125, loss = 0.01377770\n",
      "Iteration 126, loss = 0.01371455\n",
      "Iteration 127, loss = 0.01361901\n",
      "Iteration 128, loss = 0.01348885\n",
      "Iteration 129, loss = 0.01337471\n",
      "Iteration 130, loss = 0.01329534\n",
      "Iteration 131, loss = 0.01319161\n",
      "Iteration 132, loss = 0.01307325\n",
      "Iteration 133, loss = 0.01297361\n",
      "Iteration 134, loss = 0.01290154\n",
      "Iteration 135, loss = 0.01280245\n",
      "Iteration 136, loss = 0.01271681\n",
      "Iteration 137, loss = 0.01262171\n",
      "Iteration 138, loss = 0.01256931\n",
      "Iteration 139, loss = 0.01244187\n",
      "Iteration 140, loss = 0.01234056\n",
      "Iteration 141, loss = 0.01225679\n",
      "Iteration 142, loss = 0.01222734\n",
      "Iteration 143, loss = 0.01210771\n",
      "Iteration 144, loss = 0.01210701\n",
      "Iteration 145, loss = 0.01193333\n",
      "Iteration 146, loss = 0.01187697\n",
      "Iteration 147, loss = 0.01179767\n",
      "Iteration 148, loss = 0.01169855\n",
      "Iteration 149, loss = 0.01164048\n",
      "Iteration 150, loss = 0.01156064\n",
      "Iteration 151, loss = 0.01148959\n",
      "Iteration 152, loss = 0.01138028\n",
      "Iteration 153, loss = 0.01132211\n",
      "Iteration 154, loss = 0.01129986\n",
      "Iteration 155, loss = 0.01117716\n",
      "Iteration 156, loss = 0.01113350\n",
      "Iteration 157, loss = 0.01105647\n",
      "Iteration 158, loss = 0.01104004\n",
      "Iteration 159, loss = 0.01092258\n",
      "Iteration 160, loss = 0.01084161\n",
      "Iteration 161, loss = 0.01079572\n",
      "Iteration 162, loss = 0.01072445\n",
      "Iteration 163, loss = 0.01064291\n",
      "Iteration 164, loss = 0.01059034\n",
      "Iteration 165, loss = 0.01055622\n",
      "Iteration 166, loss = 0.01047092\n",
      "Iteration 167, loss = 0.01043451\n",
      "Iteration 168, loss = 0.01035355\n",
      "Iteration 169, loss = 0.01027127\n",
      "Iteration 170, loss = 0.01025827\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(15,), learning_rate='constant',\n",
       "       learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(15,),\n",
    "                    activation = 'logistic',\n",
    "                    solver = 'sgd',\n",
    "                    tol = 1e-4,\n",
    "                    learning_rate_init = .1,\n",
    "                    verbose=True)\n",
    "\n",
    "mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 0 5 3 6 9 6 1 7]\n",
      "[1 4 0 5 3 6 9 6 1 7]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = mlp.predict(x_test)\n",
    "print(predictions[:10])\n",
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>79</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>82</td>\n",
       "      <td>88</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>69</td>\n",
       "      <td>83</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0   1   2   3   4   5   6   7   8   9  All\n",
       "True                                                  \n",
       "0          76   0   0   0   0   1   1   0   1   0   79\n",
       "1           0  69   0   1   1   0   0   0   4   5   80\n",
       "2           2   0  71   2   0   0   0   1   1   0   77\n",
       "3           0   2   1  66   0   4   0   4   2   0   79\n",
       "4           0   3   0   0  78   0   2   0   0   0   83\n",
       "5           0   0   0   0   2  79   1   0   0   0   82\n",
       "6           0   1   0   0   0   0  79   0   0   0   80\n",
       "7           0   1   0   0   1   0   0  77   0   1   80\n",
       "8           0   8   0   1   0   3   0   2  61   1   76\n",
       "9           1   0   0   3   0   1   0   0   0  76   81\n",
       "All        79  84  72  73  82  88  83  84  69  83  797"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.crosstab(y_test, predictions, rownames=['True'], colnames = ['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1288, 1471, 1485, 1495, 1514]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import datasets\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# while True:\n",
    "#     if y_test==1 and predictions==9:\n",
    "#         plt.imshow(digits.images[y_test.getfield], cmap='binary')\n",
    "#         plt.title(y_test)\n",
    "#         plt.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "a = []\n",
    "for i in range(0, len(y_test)):\n",
    "    if y_test[i] == 1 and predictions[i] == 9:\n",
    "        a.append(i+1000)\n",
    "print(a)\n",
    "#     print(str(y_test[i]) + \" : \" + str(predictions[i] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "for i in range(0,len(a)):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(digits.images[a[i]], cmap='binary')\n",
    "    plt.title(digits.target[a[i]])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
